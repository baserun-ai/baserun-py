class SpanAttributes:
    BASERUN_RUN = "baserun.run"
    BASERUN_SESSION_ID = "baserun.session_id"
    BASERUN_USER_ID = "baserun.user_id"
    BASERUN_TEMPLATE_VERSION_ID = "baserun.template_version_id"
    BASERUN_TEMPLATE_STRING = "baserun.template_string"
    BASERUN_TEMPLATE_PARAMETERS = "baserun.template_parameters"
    # Superset of opentelemetry-semconv-llm
    LLM_COMPLETION_ID = "llm.completion_id"
    LLM_VENDOR = "llm.vendor"
    LLM_REQUEST_TYPE = "llm.request.type"
    LLM_REQUEST_MODEL = "llm.request.model"
    LLM_RESPONSE_MODEL = "llm.response.model"
    LLM_REQUEST_MAX_TOKENS = "llm.request.max_tokens"
    LLM_USAGE_TOTAL_TOKENS = "llm.usage.total_tokens"
    LLM_USAGE_COMPLETION_TOKENS = "llm.usage.completion_tokens"
    LLM_USAGE_PROMPT_TOKENS = "llm.usage.prompt_tokens"
    LLM_TEMPERATURE = "llm.temperature"
    LLM_TOP_P = "llm.top_p"
    LLM_TOP_K = "llm.top_k"
    LLM_FREQUENCY_PENALTY = "llm.frequency_penalty"
    LLM_PRESENCE_PENALTY = "llm.presence_penalty"
    LLM_PROMPTS = "llm.prompts"
    LLM_COMPLETIONS = "llm.completions"
    LLM_CHAT_STOP_SEQUENCES = "llm.chat.stop_sequences"
    LLM_FUNCTION_CALL = "llm.function_call"
    LLM_FUNCTIONS = "llm.functions"
    LLM_N = "llm.n"
    LLM_RESPONSE_FORMAT = "llm.response_format"
    LLM_SEED = "llm.seed"
    LLM_STREAM = "llm.stream"
    LLM_STOP = "llm.stop"
    LLM_LOGIT_BIAS = "llm.logit_bias"
    LLM_TOOL_CHOICE = "llm.tool_choice"
    LLM_TOOLS = "llm.tools"
    LLM_USER = "llm.user"
    LLM_BEST_OF = "llm.best_of"
    LLM_LOGPROBS = "llm.logprobs"
    LLM_SUFFIX = "llm.suffix"
    LLM_ECHO = "llm.echo"

    OPENAI_API_VERSION = "openai.api_version"
    OPENAI_API_BASE = "openai.api_base"
    OPENAI_API_TYPE = "openai.api_type"

    ANTHROPIC_LOG_ID = "anthropic.log_id"


ANTHROPIC_VENDOR_NAME = "Anthropic"
OPENAI_VENDOR_NAME = "OpenAI"
